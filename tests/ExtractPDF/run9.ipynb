{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\uniflow\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "import sys\n",
    "from llama_parse import LlamaParse\n",
    "from uniflow.flow.client import TransformClient\n",
    "from uniflow.flow.config import TransformOpenAIConfig\n",
    "from uniflow.flow.config import OpenAIModelConfig\n",
    "from uniflow.op.prompt import PromptTemplate, Context\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .env file\n",
    "dotenv_path = 'D:/apikeys/.env'  \n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "# Retrieve the API key from the environment\n",
    "openAI_API = os.getenv('OPENAI_API_KEY')\n",
    "llama_API = os.getenv('LLAMA_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import file\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "thisfile_dir = os.getcwd()#if put this file in tests/ExtractPDF\n",
    "dir_cur = os.path.join(thisfile_dir, '..', '..')\n",
    "\n",
    "pdf_file = \"test.pdf\"\n",
    "input_file = os.path.join(f\"{dir_cur}/data/Reports\", pdf_file)\n",
    "\n",
    "# Get the base name of the file\n",
    "base_name = os.path.basename(input_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 2b668fbd-c450-48bd-8b53-36fb1ee19e19\n"
     ]
    }
   ],
   "source": [
    "# Transform PDF\n",
    "nest_asyncio.apply()\n",
    "\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = llama_API\n",
    "\n",
    "documents = LlamaParse(result_type=\"markdown\").load_data(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the text into one str\n",
    "all_text = []\n",
    "for doc in documents:\n",
    "    all_text.append(doc.text)\n",
    "\n",
    "merged_doc = '\\n\\n'.join(all_text)\n",
    "\n",
    "# Save as txt\n",
    "txt_output_path = os.path.join(dir_cur, 'outputs/llama_parsed', f'{base_name}.txt')\n",
    "with open(txt_output_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(merged_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set prompt and example\n",
    "identify_prompt = PromptTemplate(\n",
    "    instruction=\"\"\"Extract and directly copy any text-based content or tables specifically containing ESG information that could be used for a data analysis. Focus on capturing content that is comprehensive.\n",
    "    \"\"\",\n",
    "    few_shot_prompt=[\n",
    "        Context(\n",
    "            context=\"The company reported a total of 10,001 promtCO2e of Scope 1 emissions in 2020.\"\"\"\n",
    "    )]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "standardize_prompt = PromptTemplate(\n",
    "    instruction=\"\"\"Standardize the ESG contents or tables into a structured data frame that includes: 'label' , 'metric', 'unit', 'year' and 'value' (numerical value). \n",
    "    Here is the reference for 'label', 'metric' and 'unit': \n",
    "    {\n",
    "  \"Label\": {\n",
    "    \"Greenhouse Gas Emissions\": [\n",
    "      {\n",
    "        \"metric\": \"Total\",\"Scope 1\",\"Scope 2\",\"Scope 3\"\n",
    "        \"unit\": \"tCO2e\"\n",
    "      },\n",
    "      {\n",
    "        \"metric\": \"Emission intensities of total\",\"Emission intensities of Scope 1\",\"Emission intensities of Scope 2\",\"Emission intensities of Scope 3\"\n",
    "        \"unit\": \"tCO2e\"\n",
    "      }\n",
    "    ],\n",
    "    \"Energy Consumption\": [\n",
    "      {\n",
    "        \"metric\": \"Total energy consumption\",\n",
    "        \"unit\": \"MWhs\", \"GJ\"\n",
    "      },\n",
    "      {\n",
    "        \"metric\": \"Energy consumption intensity\",\n",
    "        \"unit\": \"MWhs\", \"GJ\"\n",
    "      }\n",
    "    ],\n",
    "    \"Water Consumption\": [\n",
    "      {\n",
    "        \"metric\": \"Total water consumption\",\n",
    "        \"unit\": \"ML\", \"m³\"\n",
    "      },\n",
    "      {\n",
    "        \"metric\": \"Water consumption intensity\",\n",
    "        \"unit\": \"ML\", \"m³\"\n",
    "      }\n",
    "    ],\n",
    "    \"Waste Generation\": {\n",
    "      \"metric\": \"Total waste generated\",\n",
    "      \"unit\": \"t\"\n",
    "    },\n",
    "    \"Gender Diversity\": [\n",
    "      {\n",
    "        \"metric\": \"Current employees by gender\",\n",
    "        \"unit\": \"Male Percentage (%)\",\"Female Percentage (%)\",\"Others Percentage (%)\"\n",
    "      },\n",
    "      {\n",
    "        \"metric\": \"New hires and turnover by gender\",\n",
    "        \"unit\": \"Male Percentage (%)\",\"Female Percentage (%)\",\"Others Percentage (%)\"\n",
    "      }\n",
    "    ],\n",
    "    \"Age-Based Diversity\": [\n",
    "      {\n",
    "        \"metric\": \"Current employees by age groups\",\n",
    "        \"unit\": \"Baby Boomers (%)\",\"Gen Xers (%)\",\"Millennials (%)\",\"Gen Z (%)\"\n",
    "      },\n",
    "      {\n",
    "        \"metric\": \"New hires and turnover by age groups\",\n",
    "        \"unit\": \"Baby Boomers (%)\",\"Gen Xers (%)\",\"Millennials (%)\",\"Gen Z (%)\"\n",
    "      }\n",
    "    ],\n",
    "    \"Employment\": [\n",
    "      {\n",
    "        \"metric\": \"Total employee turnover\",\n",
    "        \"unit\": \"Number\", \"Percentage (%)\"\n",
    "      },\n",
    "      {\n",
    "        \"metric\": \"Total number of employees\",\n",
    "        \"unit\": \"Number\"\n",
    "      }\n",
    "    ],\n",
    "    \"Development & Training\": [\n",
    "      {\n",
    "        \"metric\": \"Average training hours per employee\",\n",
    "        \"unit\": \"Hours/No. of employees\"\n",
    "      },\n",
    "      {\n",
    "        \"metric\": \"Average training hours per employee by gender\",\n",
    "        \"unit\": \"Male Hours/No. of employees\", \"Female Hours/No. of employees\"\n",
    "      }\n",
    "    ],\n",
    "    \"Occupational Health & Safety\": [\n",
    "      {\n",
    "        \"metric\": \"Fatalities\",\n",
    "        \"unit\": \"Number of cases\"\n",
    "      },\n",
    "      {\n",
    "        \"metric\": \"High-consequence injuries\",\n",
    "        \"unit\": \"Number of cases\"\n",
    "      },\n",
    "      {\n",
    "        \"metric\": \"Recordable injuries\",\n",
    "        \"unit\": \"Number of cases\"\n",
    "      }\n",
    "    ],\n",
    "    \"Recordable work-related illnesses\": {\n",
    "      \"metric\": \"Number of recordable work-related illnesses or health conditions\",\n",
    "      \"unit\": \"Number of cases\"\n",
    "    },\n",
    "    \"Board Composition\": [\n",
    "      {\n",
    "        \"metric\": \"Board independence\",\n",
    "        \"unit\": \"Percentage (%)\"\n",
    "      },\n",
    "      {\n",
    "        \"metric\": \"Women on the board\",\n",
    "        \"unit\": \"Percentage (%)\"\n",
    "      }\n",
    "    ],\n",
    "    \"Management Diversity\": {\n",
    "      \"metric\": \"Women in the management team\",\n",
    "      \"unit\": \"Percentage (%)\"\n",
    "    },\n",
    "    \"Ethical Behaviour\": [\n",
    "      {\n",
    "        \"metric\": \"Anti-corruption disclosures\",\n",
    "        \"unit\": \"Discussion and number\"\n",
    "      },\n",
    "      {\n",
    "        \"metric\": \"Anti-corruption training for employees\",\n",
    "        \"unit\": \"Number and Percentage (%)\"\n",
    "      }\n",
    "    ],\n",
    "    \"Certifications\": {\n",
    "      \"metric\": \"List of relevant certifications\",\n",
    "      \"unit\": \"List\"\n",
    "    },\n",
    "    \"Alignment with Frameworks\": {\n",
    "      \"metric\": \"Alignment with frameworks and disclosure practices\"\n",
    "    },\n",
    "    \"Assurance\": {\n",
    "      \"metric\": \"Assurance of sustainability report\",\n",
    "      \"unit\": \"Internal\",\"External\",\"None\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "    Return the standardized data frame for analysis.\n",
    "    \"\"\",\n",
    "    few_shot_prompt=[\n",
    "        Context(\n",
    "            label=\"Greenhouse Gas Emissions\"\"\",\n",
    "            metrics=\"Scope 1\"\"\",\n",
    "            unit=\"tCO2e\"\"\",\n",
    "            year=\"2020\"\"\",\n",
    "            value=10001\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set AI config\n",
    "identify_config = TransformOpenAIConfig(\n",
    "    prompt_template=identify_prompt,\n",
    "    model_config=OpenAIModelConfig(\n",
    "        model_name = 'gpt-4o-mini',\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    ),\n",
    ")\n",
    "\n",
    "standardize_config = TransformOpenAIConfig(\n",
    "    prompt_template=standardize_prompt,\n",
    "    model_config=OpenAIModelConfig(\n",
    "        model_name = 'gpt-4o-2024-08-06',\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    ),\n",
    ")\n",
    "\n",
    "load_dotenv()  \n",
    "os.environ[\"OPENAI_API_KEY\"] = openAI_API\n",
    "\n",
    "identify_client = TransformClient(identify_config)\n",
    "standardize_client = TransformClient(standardize_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the extracted esg contents as a dictionary\n",
    "ESG_contents = {}\n",
    "\n",
    "for idx, doc in enumerate(documents):\n",
    "    input_page = [\n",
    "        Context(\n",
    "            context=doc.text,\n",
    "        )]\n",
    "\n",
    "    ESG_contents[idx] = identify_client.run(input_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure the extracted esg contents as a list\n",
    "def extract_esg_contents(esg_contents):\n",
    "    extracted_responses = []\n",
    "\n",
    "    try:\n",
    "        # Iterate through the keys of the ESG_contents dictionary\n",
    "        for key in esg_contents:\n",
    "            items = esg_contents[key]\n",
    "            \n",
    "            # Iterate through each item in the list associated with the current key\n",
    "            for item in items:\n",
    "                output_list = item.get('output', [])\n",
    "                \n",
    "                # Iterate through each output item\n",
    "                for output_item in output_list:\n",
    "                    response_list = output_item.get('response', [])\n",
    "                    \n",
    "                    # Append each response item to the extracted_responses list\n",
    "                    for response_item in response_list:\n",
    "                        extracted_responses.append(response_item)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting response content: {e}\")\n",
    "\n",
    "    return extracted_responses\n",
    "\n",
    "extracted_contents = extract_esg_contents(ESG_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run step 2 and store the json output in a dictionary \n",
    "output = {}\n",
    "\n",
    "for idx, item in enumerate(extracted_contents):\n",
    "    sentence = [\n",
    "        Context(\n",
    "            context=item\n",
    "        )\n",
    "        ]\n",
    "\n",
    "    output[idx] = standardize_client.run(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the json output into a DataFrame\n",
    "unit = []\n",
    "label = []\n",
    "year =[]\n",
    "metric = []\n",
    "value = []\n",
    "for out in output.values():  \n",
    "    for item in out:\n",
    "        for i in item.get('output', []):\n",
    "            for response in i.get('response', []):\n",
    "                for key in response:\n",
    "                                if isinstance(response[key], list) and len(response[key]) > 0:\n",
    "                                    for res in response[key]:  \n",
    "                                        if all(k in res for k in [ 'unit','label', 'year', 'metric', 'value']):\n",
    "                                            unit.append(res['unit'])\n",
    "                                            label.append(res['label'])\n",
    "                                            year.append(res['year'])\n",
    "                                            metric.append(res['metric'])\n",
    "                                            value.append(res['value'])\n",
    "                    \n",
    "df = pd.DataFrame({\n",
    "    'label': label,\n",
    "    'metric': metric,\n",
    "    'unit' : unit,\n",
    "    'year':year,\n",
    "    'value' :value\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delet the example data\n",
    "df_filtered = df[df['value'] != 10001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#show the dataframe\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame as Excel file\n",
    "excel_output_path = os.path.join(dir_cur, 'outputs/extracted_data', f'{base_name}.xlsx')\n",
    "df_filtered.to_excel(excel_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uniflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
